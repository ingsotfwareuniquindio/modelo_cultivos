# MODELO TOP 5 CULTIVOS - CAMBIO R√ÅPIDO
# =====================================
# Usar dataset limpio existente, solo filtrar a Top 5

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import precision_score, recall_score, f1_score
import joblib
import warnings
warnings.filterwarnings('ignore')

print("üéØ MODELO TOP 5 CULTIVOS - PRUEBA R√ÅPIDA")
print("=" * 50)

# 1. CARGAR DATASET LIMPIO (YA PERFECTO DEL PASO 2)
print("\nüìÇ 1. CARGANDO DATASET LIMPIO...")
df_clean = pd.read_csv('dataset_cleaned_ready_for_ml.csv')
print(f"‚úÖ Dataset limpio cargado: {len(df_clean):,} registros")

# 2. FILTRAR SOLO TOP 5 CULTIVOS
print("\nüîç 2. FILTRANDO A TOP 5 CULTIVOS...")

# Los 5 cultivos m√°s frecuentes de tu an√°lisis
TOP_5_CULTIVOS = ['Cacao', 'Pastos', 'Aguacate', 'Ca√±a panelera/azucar', 'Caf√©']

print("üèÜ Top 5 cultivos seleccionados:")
for i, cultivo in enumerate(TOP_5_CULTIVOS, 1):
    count = (df_clean['Cultivo'] == cultivo).sum()
    percentage = (count / len(df_clean)) * 100
    print(f"   {i}. {cultivo:<25} | {count:5,} registros ({percentage:4.1f}%)")

# Filtrar dataset
df_top5 = df_clean[df_clean['Cultivo'].isin(TOP_5_CULTIVOS)].copy()

print(f"\nüìä Resultado del filtro:")
print(f"   Dataset original: {len(df_clean):,} registros (20 cultivos)")
print(f"   Dataset filtrado: {len(df_top5):,} registros (5 cultivos)")
print(f"   Conservado: {len(df_top5)/len(df_clean)*100:.1f}% de los datos")

# 3. PREPARAR FEATURES Y TARGET
print("\nüîß 3. PREPARANDO DATOS...")

# Features (las mismas 8 variables)
feature_columns = [
    'pH agua:suelo 2,5:1,0',
    'Materia org√°nica (MO) %',
    'F√≥sforo (P) Bray II mg/kg',
    'Potasio (K) intercambiable cmol(+)/kg',
    'Calcio (Ca) intercambiable cmol(+)/kg',
    'Magnesio (Mg) intercambiable cmol(+)/kg',
    'Topografia_encoded',
    'Drenaje_encoded'
]

X = df_top5[feature_columns]
y = df_top5['Cultivo']

print(f"‚úÖ Features: {X.shape}")
print(f"‚úÖ Target: {y.shape}")
print(f"‚úÖ Cultivos √∫nicos: {y.nunique()}")

# Verificar distribuci√≥n de cultivos
print(f"\nüìà Distribuci√≥n final de cultivos:")
cultivo_dist = y.value_counts()
for cultivo, count in cultivo_dist.items():
    percentage = (count / len(y)) * 100
    print(f"   üå± {cultivo:<25} | {count:5,} registros ({percentage:4.1f}%)")

# 4. DIVISI√ìN TRAIN/TEST
print("\nüîÄ 4. DIVISI√ìN TRAIN/TEST...")

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print(f"‚úÖ Train: {len(X_train):,} registros")
print(f"‚úÖ Test:  {len(X_test):,} registros")

# 5. ENTRENAR MODELO OPTIMIZADO
print("\nüöÄ 5. ENTRENANDO MODELO TOP 5...")

# Usar par√°metros balanceados para 5 clases
rf_top5 = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,              # Un poco m√°s profundo para 5 clases
    min_samples_split=5,       # Menos restrictivo
    min_samples_leaf=2,        # Menos restrictivo
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)

print("üå≤ Par√°metros del modelo:")
print(f"   üå≥ √Årboles: {rf_top5.n_estimators}")
print(f"   üìè Profundidad: {rf_top5.max_depth}")
print(f"   üî¢ Min split: {rf_top5.min_samples_split}")
print(f"   üçÉ Min hoja: {rf_top5.min_samples_leaf}")

# Entrenar
import time
start_time = time.time()
rf_top5.fit(X_train, y_train)
training_time = time.time() - start_time

print(f"‚úÖ Modelo entrenado en {training_time:.2f} segundos")

# 6. EVALUAR MODELO
print("\nüìä 6. EVALUACI√ìN DEL MODELO TOP 5:")
print("-" * 40)

# Predicciones
y_train_pred = rf_top5.predict(X_train)
y_test_pred = rf_top5.predict(X_test)

# M√©tricas principales
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)
overfitting = abs(train_accuracy - test_accuracy)

print(f"üéØ Precisi√≥n Train: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
print(f"üéØ Precisi√≥n Test:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
print(f"üìà Overfitting:    {overfitting:.4f} ({overfitting*100:.2f}%)")

# M√©tricas detalladas
precision_weighted = precision_score(y_test, y_test_pred, average='weighted')
recall_weighted = recall_score(y_test, y_test_pred, average='weighted')
f1_weighted = f1_score(y_test, y_test_pred, average='weighted')

print(f"\nüìà M√©tricas detalladas:")
print(f"üéØ Precisi√≥n: {precision_weighted:.4f} ({precision_weighted*100:.2f}%)")
print(f"üîÑ Recall:    {recall_weighted:.4f} ({recall_weighted*100:.2f}%)")
print(f"‚öñÔ∏è F1-Score:  {f1_weighted:.4f} ({f1_weighted*100:.2f}%)")

# 7. COMPARACI√ìN CON MODELO ANTERIOR
print(f"\nüÜö 7. COMPARACI√ìN CON MODELOS ANTERIORES:")
print("-" * 40)

modelos_anteriores = {
    '20 cultivos (original)': {'precision': 0.5156, 'f1': 0.5062},
    '20 cultivos (conservador)': {'precision': 0.3776, 'f1': 0.3770}
}

print("Modelo                     | Precisi√≥n | F1-Score | Cultivos")
print("-" * 65)
for nombre, metricas in modelos_anteriores.items():
    print(f"{nombre:<26} | {metricas['precision']:8.4f} | {metricas['f1']:8.4f} | 20")

print(f"{'Top 5 cultivos (nuevo)':<26} | {test_accuracy:8.4f} | {f1_weighted:8.4f} | 5")

# Calcular mejoras
mejor_anterior = max([m['precision'] for m in modelos_anteriores.values()])
mejora = test_accuracy - mejor_anterior

print(f"\nüöÄ Mejora vs mejor anterior: {mejora:+.4f} ({mejora*100:+.2f}%)")

# 8. PERFORMANCE POR CULTIVO
print(f"\nüå± 8. PERFORMANCE POR CULTIVO:")
print("-" * 40)

# Reporte detallado
classification_rep = classification_report(y_test, y_test_pred, output_dict=True)

print("Cultivo                  | Precisi√≥n | Recall | F1-Score | Soporte")
print("-" * 70)

for cultivo in TOP_5_CULTIVOS:
    if cultivo in classification_rep:
        metrics = classification_rep[cultivo]
        precision = metrics['precision']
        recall = metrics['recall']
        f1 = metrics['f1-score']
        support = int(metrics['support'])
        print(f"{cultivo:<25} | {precision:8.3f} | {recall:6.3f} | {f1:8.3f} | {support:7d}")

# 9. IMPORTANCIA DE VARIABLES
print(f"\nüîç 9. IMPORTANCIA DE VARIABLES:")
print("-" * 40)

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_top5.feature_importances_
}).sort_values('importance', ascending=False)

print("Ranking de importancia:")
for i, (_, row) in enumerate(feature_importance.iterrows(), 1):
    importance_pct = row['importance'] * 100
    bar = "‚ñà" * max(1, int(importance_pct / 3))
    print(f"{i}. {row['feature']:<35} | {importance_pct:5.2f}% {bar}")

# 10. GUARDAR MODELO TOP 5
print(f"\nüíæ 10. GUARDANDO MODELO TOP 5...")

joblib.dump(rf_top5, 'modelo_top5_cultivos.pkl')
print("‚úÖ Modelo Top 5 guardado: 'modelo_top5_cultivos.pkl'")

# Informaci√≥n completa
model_info_top5 = {
    'model': rf_top5,
    'cultivos': TOP_5_CULTIVOS,
    'feature_names': list(X.columns),
    'target_classes': list(rf_top5.classes_),
    'metrics': {
        'test_accuracy': test_accuracy,
        'precision_weighted': precision_weighted,
        'recall_weighted': recall_weighted,
        'f1_weighted': f1_weighted,
        'overfitting_score': overfitting
    },
    'data_info': {
        'training_samples': len(X_train),
        'test_samples': len(X_test),
        'total_samples': len(X),
        'original_samples': len(df_clean),
        'data_retention': len(df_top5)/len(df_clean)
    }
}

joblib.dump(model_info_top5, 'modelo_top5_info.pkl')
print("‚úÖ Info del modelo guardada: 'modelo_top5_info.pkl'")

# 11. RESUMEN FINAL
print(f"\nüéØ RESUMEN FINAL - MODELO TOP 5:")
print("=" * 50)
print(f"‚úÖ Cultivos: {len(TOP_5_CULTIVOS)} (vs 20 anteriores)")
print(f"‚úÖ Registros: {len(df_top5):,} ({len(df_top5)/len(df_clean)*100:.1f}% del dataset)")
print(f"‚úÖ Precisi√≥n: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
print(f"‚úÖ F1-Score: {f1_weighted:.4f} ({f1_weighted*100:.2f}%)")
print(f"‚úÖ Overfitting: {overfitting:.4f} ({'Controlado' if overfitting < 0.1 else 'Alto'})")
print(f"‚úÖ Tiempo: {training_time:.2f} segundos")

# Evaluaci√≥n del resultado
if test_accuracy > 0.80:
    status = "üéâ ¬°EXCELENTE!"
    recommendation = "Listo para producci√≥n"
elif test_accuracy > 0.65:
    status = "üëç BUENO"
    recommendation = "Modelo √∫til, se puede optimizar m√°s"
elif test_accuracy > 0.50:
    status = "üòê REGULAR"
    recommendation = "Funciona, pero necesita mejoras"
else:
    status = "üòû BAJO"
    recommendation = "Necesita trabajo adicional"

print(f"\n{status}")
print(f"üìã Evaluaci√≥n: {recommendation}")

# Comparaci√≥n espec√≠fica
baseline_random = 1.0 / len(TOP_5_CULTIVOS)  # 20% para 5 clases
improvement_vs_random = test_accuracy - baseline_random

print(f"\nüìä Comparaci√≥n con predicci√≥n aleatoria:")
print(f"   üé≤ Aleatoria: {baseline_random:.4f} ({baseline_random*100:.2f}%)")
print(f"   ü§ñ Tu modelo: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
print(f"   üöÄ Mejora: {improvement_vs_random:+.4f} ({improvement_vs_random*100:+.2f}%)")

if test_accuracy > 0.60:
    print(f"\nüöÄ SIGUIENTE PASO: Crear funci√≥n de predicci√≥n")
else:
    print(f"\nüîß CONSIDERACIONES: Revisar si se necesitan m√°s variables")

print(f"\n‚ú® ¬°MODELO TOP 5 COMPLETADO!")
